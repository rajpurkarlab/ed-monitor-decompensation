{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e131ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import h5py\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal #for downsampling\n",
    "import samplerate\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import os \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics import Metric\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchmetrics import R2Score, AUROC, F1Score\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# import concordance index\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e4f65-4967-428f-b600-d67f0de57d0f",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344e678-83ba-4c82-ae47-258c7b3d3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file_60 = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.csv\"\n",
    "dfy_60 = pd.read_csv(summary_file_60)\n",
    "dfy_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c644d6-8a37-40ae-88bd-cf627afb0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file_90 = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.90min.60sec.csv\"\n",
    "dfy_90 = pd.read_csv(summary_file_90)\n",
    "dfy_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622a88b-4df5-4603-a3f3-da2e5915b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file_120 = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.120min.60sec.csv\"\n",
    "dfy_120 = pd.read_csv(summary_file_120)\n",
    "dfy_120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408bf7d-e4c9-4534-be66-f7ae727317e2",
   "metadata": {},
   "source": [
    "## Run the following 3 Chunks to Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cfe37-155c-4686-ab36-643c96d566a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.h5\"\n",
    "# summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.csv\"\n",
    "h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.90min.60sec.h5\"\n",
    "summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.90min.60sec.csv\"\n",
    "# h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.120min.60sec.h5\"\n",
    "# summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.120min.60sec.csv\"\n",
    "\n",
    "dfy_hr = h5py.File(h5py_file, \"r\").get('numerics_after')[\"HR\"][\"vals\"][()]\n",
    "dfy_dbp = h5py.File(h5py_file, \"r\").get('numerics_after')[\"NBPd\"][\"vals\"][()]\n",
    "dfy_sbp = h5py.File(h5py_file, \"r\").get('numerics_after')[\"NBPs\"][\"vals\"][()]\n",
    "dfy_spO2 = h5py.File(h5py_file, \"r\").get('numerics_after')[\"SpO2\"][\"vals\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f828b3c-8206-4a8d-a471-fdaec90240a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619d73d-73d0-45a8-92bf-0f077ccc4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx_pleth = h5py.File(h5py_file, \"r\").get('waveforms')[\"Pleth\"][\"waveforms\"][()]\n",
    "dfx_ecg = h5py.File(h5py_file, \"r\").get('waveforms')[\"II\"][\"waveforms\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249fb80-5147-453a-a160-836b173483ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfx_pleth.shape)\n",
    "print(dfx_ecg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30492d72-4a57-4963-9c8e-595b2882b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy_hr = h5py.File(h5py_file, \"r\").get('numerics_after')[\"HR\"][\"vals\"][()]\n",
    "dfy_dbp = h5py.File(h5py_file, \"r\").get('numerics_after')[\"NBPd\"][\"vals\"][()]\n",
    "dfy_sbp = h5py.File(h5py_file, \"r\").get('numerics_after')[\"NBPs\"][\"vals\"][()]\n",
    "dfy_map = (dfy_sbp + 2 * dfy_dbp) / 3\n",
    "dfy_spO2 = h5py.File(h5py_file, \"r\").get('numerics_after')[\"SpO2\"][\"vals\"][()]\n",
    "dfy_hr_labels = np.nanmax(dfy_hr, axis = 1).reshape(dfy_hr.shape[0], 1)\n",
    "dfy_sbp_labels = np.nanmin(dfy_sbp, axis = 1).reshape(dfy_sbp.shape[0], 1)\n",
    "dfy_dbp_labels = np.nanmin(dfy_dbp, axis = 1).reshape(dfy_dbp.shape[0], 1)\n",
    "dfy_map_labels = np.nanmin(dfy_map, axis = 1).reshape(dfy_map.shape[0], 1)\n",
    "dfy_spO2_labels = np.nanmin(dfy_spO2, axis = 1).reshape(dfy_spO2.shape[0], 1)\n",
    "idx_zero_hr = np.where(dfy_hr_labels == 0)[0]\n",
    "idx_zero_sbp = np.where(dfy_sbp_labels == 0)[0]\n",
    "idx_zero_dbp = np.where(dfy_dbp_labels == 0)[0]\n",
    "idx_zero_spO2 = np.where(dfy_spO2_labels == 0)[0]\n",
    "idx_nan_hr =  np.where(np.isnan(dfy_hr_labels))[0]\n",
    "idx_nan_sbp =  np.where(np.isnan(dfy_sbp_labels))[0]\n",
    "idx_nan_dbp =  np.where(np.isnan(dfy_dbp_labels))[0]\n",
    "idx_nan_spO2 =  np.where(np.isnan(dfy_spO2_labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d57b4-b6c8-4260-97b5-88ea533a593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.read_csv(summary_file)\n",
    "labels_df = pd.DataFrame({\"CSN\": dfy.patient_id, \"HR\":dfy_hr_labels.reshape(dfy_hr_labels.shape[0]), \"SBP\":dfy_sbp_labels.reshape(dfy_sbp_labels.shape[0]), \n",
    "                          \"DBP\":dfy_dbp_labels.reshape(dfy_dbp_labels.shape[0]), \"MAP\":dfy_map_labels.reshape(dfy_map_labels.shape[0]), \"SPO2\":dfy_spO2_labels.reshape(dfy_spO2_labels.shape[0])})\n",
    "labels_df.to_csv('final_90min_labels_053022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57568262-707e-4d0a-8f34-4535f5bae845",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in list(labels_df.columns):\n",
    "    print(f\"there are {labels_df[column].isna().sum()} na's in {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749c874-8df8-4b05-9de7-335fce292cf5",
   "metadata": {},
   "source": [
    "## End of Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590f7f0-5d7f-4984-9452-0a4c6db83a71",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8000597-e86e-4662-b04d-8671242d8715",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split(h5py_file, summary_file, label_file, time = \"60\", split_type = \"all\"):\n",
    "    \"\"\"\n",
    "    generates initial splits that do not have any NaN or 0s\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(label_file)\n",
    "    dfx_pleth = h5py.File(h5py_file, \"r\").get('waveforms')[\"Pleth\"][\"waveforms\"][()]\n",
    "    dfx_ecg = h5py.File(h5py_file, \"r\").get('waveforms')[\"II\"][\"waveforms\"][()]\n",
    "    combined = np.stack((dfx_pleth, dfx_ecg))\n",
    "    dfx = np.moveaxis(combined, [0, 1, 2], [1, 0, 2])\n",
    "    dfy = pd.read_csv(summary_file)\n",
    "    \n",
    "    \n",
    "    indices = dfy.index[(dfy[\"II_quality\"] == 1) & (dfy['Pleth_quality'] == 1)].tolist()\n",
    "    print(\"number of patients dropped bc of waveform quality: {}\".format(dfy.shape[0] - len(indices)))\n",
    "    print(\"Old Shape = {}\".format(dfy.shape))\n",
    "    print(\"Old data shape = {}\".format(dfx.shape))\n",
    "    \n",
    "    dfy_hr_labels = np.array(labels['HR']).reshape(labels.shape[0], 1)\n",
    "    dfy_spO2_labels = np.array(labels['SPO2']).reshape(labels.shape[0], 1)\n",
    "    dfy_map_labels = np.array(labels['MAP']).reshape(labels.shape[0], 1)\n",
    "\n",
    "    idx_zero_hr = np.where(dfy_hr_labels == 0)[0]\n",
    "    idx_zero_map = np.where(dfy_map_labels == 0)[0]\n",
    "    idx_zero_spO2 = np.where(dfy_spO2_labels == 0)[0]\n",
    "\n",
    "    idx_nan_hr =  np.where(np.isnan(dfy_hr_labels))[0]\n",
    "    idx_nan_map =  np.where(np.isnan(dfy_map_labels))[0]\n",
    "    idx_nan_spO2 =  np.where(np.isnan(dfy_spO2_labels))[0]\n",
    "\n",
    "    \n",
    "    if split_type == \"all\":\n",
    "        idx_zero = np.concatenate((idx_zero_hr, idx_zero_map, idx_zero_spO2))\n",
    "        idx_zero = np.unique(idx_zero)\n",
    "        idx_nan = np.concatenate((idx_nan_hr, idx_nan_map, idx_nan_spO2))\n",
    "        idx_nan = np.unique(idx_nan)\n",
    "        idx_drop = np.unique(np.concatenate((idx_zero, idx_nan)))\n",
    "        to_drop = list(idx_drop)\n",
    "        final_ind = list(set(indices) - set(to_drop))\n",
    "        dfy_labels = np.concatenate((np.array(labels['HR'].iloc[final_ind]), \n",
    "                                    np.array(labels['SPO2'].iloc[final_ind]), \n",
    "                                    np.array(labels['MAP'].iloc[final_ind])))\n",
    "        dfx = dfx[final_ind]\n",
    "        dfy = dfy.iloc[final_ind]\n",
    "    \n",
    "    if split_type == \"HR\":\n",
    "        idx_zero = np.unique(idx_zero_hr)\n",
    "        idx_nan = np.unique(idx_nan_hr)\n",
    "        idx_drop = np.unique(np.concatenate((idx_zero, idx_nan)))\n",
    "        to_drop = list(idx_drop)\n",
    "        final_ind = list(set(indices) - set(to_drop))\n",
    "        dfy_labels = np.array(labels['HR'].iloc[final_ind])\n",
    "        dfx = dfx[final_ind]\n",
    "        dfy = dfy.iloc[final_ind]\n",
    "        \n",
    "    if split_type == \"MAP\":\n",
    "        idx_zero = np.unique(idx_zero_map)\n",
    "        idx_nan = np.unique(idx_nan_map)\n",
    "        idx_drop = np.unique(np.concatenate((idx_zero, idx_nan)))\n",
    "        to_drop = list(idx_drop)\n",
    "        final_ind = list(set(indices) - set(to_drop))\n",
    "        dfy_labels = np.array(labels['MAP'].iloc[final_ind])\n",
    "        dfx = dfx[final_ind]\n",
    "        dfy = dfy.iloc[final_ind]\n",
    "    \n",
    "    if split_type == \"SPO2\":\n",
    "        idx_zero = np.unique(idx_zero_spO2)\n",
    "        idx_nan = np.unique(idx_nan_spO2)\n",
    "        idx_drop = np.unique(np.concatenate((idx_zero, idx_nan)))\n",
    "        to_drop = list(idx_drop)\n",
    "        final_ind = list(set(indices) - set(to_drop))\n",
    "        dfy_labels = np.array(labels['SPO2'].iloc[final_ind])\n",
    "        dfx = dfx[final_ind]\n",
    "        dfy = dfy.iloc[final_ind]\n",
    "\n",
    "   \n",
    "    print(\"Number in Set = {}\".format(dfx.shape[0]))\n",
    "    print(\"New Data Shape = {}\".format(dfx.shape))\n",
    "\n",
    "    idx_zero = np.where(dfy_labels == 0)[0]\n",
    "    idx_nan =  np.where(np.isnan(dfy_labels))[0]\n",
    "\n",
    "    print(\"num 0 to drop now = {}\".format(len(idx_zero)))\n",
    "    print(\"num NaN to drop now = {}\".format(len(idx_nan)))\n",
    "\n",
    "\n",
    "    dfy_all = dfy.copy().sort_values(by=['alignment_time'])\n",
    "    train_len = int(np.ceil(dfy_all.shape[0] * 0.875))\n",
    "    dfx_trainval = dfx[0:train_len]\n",
    "    dfy_trainval = dfy_all.iloc[0:train_len]\n",
    "    dfy_label_placeholder_trainval = np.random.rand(dfy_trainval.shape[0])\n",
    "    xtest = dfx[train_len:]\n",
    "    # ytest = np.array(dfy_all.iloc[train_len:].labels)\n",
    "    ytest_all = dfy_all.iloc[train_len:]\n",
    "    \n",
    "    # New splitter\n",
    "    splitter_train = GroupShuffleSplit(test_size= 0.125 / 0.875, n_splits=1, random_state = 7)\n",
    "\n",
    "    split = splitter_train.split(dfx_trainval, dfy_label_placeholder_trainval, groups=dfy_trainval['patient_id'])\n",
    "    train_inds, val_inds = next(split)\n",
    "\n",
    "    xtrain = dfx_trainval[train_inds]\n",
    "    # ytrain = dfy_label_placeholder_trainval[train_inds]\n",
    "    ytrain_all = dfy_trainval.iloc[train_inds]\n",
    "\n",
    "    xval = dfx_trainval[val_inds]\n",
    "    # yval = dfy_label_placeholder_trainval[val_inds]\n",
    "    yval_all = dfy_trainval.iloc[val_inds]\n",
    "\n",
    "    # generate splits\n",
    "    # Sets of pt ids\n",
    "    pt_ids_train = set(ytrain_all['patient_id'])\n",
    "    pt_ids_val = set(yval_all['patient_id'])\n",
    "    pt_ids_test = set(ytest_all['patient_id'])\n",
    "    print('intersections of patient ids = {}'.format(pt_ids_train.intersection(pt_ids_val, pt_ids_test)))\n",
    "\n",
    "    d = {'train_ids':list(pt_ids_train), 'val_ids':list(pt_ids_val), 'test_ids':list(pt_ids_test)}\n",
    "    # print(\"My Patient ID Dictionary :\", d)\n",
    "    f = open(\"final_ptid_splits_noNaN_\" + split_type + \"_\" + time + \".json\", \"w\")\n",
    "    json.dump(d, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdbc3b-85fc-4d38-8ead-fc36b297ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITS\n",
    "h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.h5\"\n",
    "summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.csv\"\n",
    "label_file = \"final_60min_labels_052722.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69be79-0f22-4ff2-b5fe-4a2e16098eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(h5py_file, summary_file, label_file, split_type=\"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e118f2-45c4-4e14-bb88-1ac43e3beacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(h5py_file, summary_file, label_file, split_type=\"MAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76a3cb-3cce-4087-b03b-bc569254ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(h5py_file, summary_file, label_file, split_type=\"SPO2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5e19f-36aa-496c-809e-451e5f2fc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split(h5py_file, summary_file, label_file, split_type=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39836ef-223e-4063-9622-6b70f24dd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITS 90 min\n",
    "h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.90min.60sec.h5\"\n",
    "summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.90min.60sec.csv\"\n",
    "label_file = \"final_90min_labels_053022.csv\"\n",
    "\n",
    "split(h5py_file, summary_file, label_file, time = \"90min\", split_type=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81d667-bcda-4091-995e-c93aea5d9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITS 120 min\n",
    "h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.120min.60sec.h5\"\n",
    "summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.120min.60sec.csv\"\n",
    "label_file = \"final_120min_labels_053022.csv\"\n",
    "\n",
    "split(h5py_file, summary_file, label_file, time = \"120min\", split_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951eb007-3deb-41ba-8c93-36733246a8c1",
   "metadata": {},
   "source": [
    "### Double check that patients we dropped actually should have been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178ea08-9c22-4aaa-bf79-81f69bf46658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped patients \n",
    "h5py_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.h5\"\n",
    "summary_file = \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.csv\"\n",
    "label_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_60min_labels_052722.csv\"\n",
    "split_file = \"final_ptid_splits_noNaN_all.json\"\n",
    "\n",
    "all_pts = list(np.array(pd.read_csv(summary_file).patient_id))\n",
    "\n",
    "with open('/deep/group/ed-monitor-self-supervised/test_models_v1/' + split_file) as json_file:\n",
    "    splits = json.load(json_file) \n",
    "\n",
    "    \n",
    "in_nan_all = list(np.concatenate((np.array(splits['train_ids']), \n",
    "                            np.array(splits['val_ids']), \n",
    "                            np.array(splits['test_ids']))))\n",
    "\n",
    "dropped = np.array(list(set(all_pts) - set(in_nan_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f703ad-dda2-4836-ae48-71de375e7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9084df-5295-42a7-818b-c9fd6968d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pts = np.array(all_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83e49b-e17b-48b7-a4d8-6ba384515e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0606e2e-cdc0-4083-af5b-d23cd0949bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_to_examine = np.where(np.isin(all_pts, dropped))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f384cb-9eb0-4b1e-a325-ab3e7d2ead89",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_to_examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c96f6-1f9a-4f9f-a198-ce865f65c2fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475554ec-37e3-4e6c-9a29-c461094788e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(all_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d04fb-b346-475c-9c49-ecbe96c0d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_to_examine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07f9dc-9aa3-4131-a2af-bbe96ab44a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2f0f1-77bd-457c-8aa4-6532ba6ba69b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def examine_one(indicies_to_examine, labels_file, summary_file, h5py_file=None):\n",
    "\n",
    "    labels = pd.read_csv(labels_file)\n",
    "    summary = pd.read_csv(summary_file)\n",
    "    choice = np.random.randint(indicies_to_examine.shape[0], size=1)[0]\n",
    "    print(labels.iloc[indicies_to_examine[choice]])\n",
    "    print(f\"II_qual = {summary.iloc[indicies_to_examine[choice]].II_quality}\\nPleth_qual = {summary.iloc[indicies_to_examine[choice]].Pleth_quality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d11936-3f16-4e52-b88c-4f9f111a8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_one(indicies_to_examine, \n",
    "            \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_60min_labels_052722.csv\", \n",
    "            \"/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4b984-d083-4ca0-b3fb-ff7fa8b0d970",
   "metadata": {},
   "source": [
    "## Final Task-Specific Splits (remove all who present abnormal initially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7d7f4-a10e-4b08-a1e3-b79cc576b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_abnormals(split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, split_type, time=\"60min\"):\n",
    "    hr_csns = set(list(pd.read_csv(normal_hr_csn_file)['patient_id']))\n",
    "    map_csns = set(list(pd.read_csv(normal_map_csn_file)['patient_id']))\n",
    "    spo2_csns = set(list(pd.read_csv(normal_spo2_csn_file)['patient_id']))\n",
    "\n",
    "    print(\"length of hr_csns = {}\".format(len(hr_csns)))\n",
    "    print(\"length of map_csns = {}\".format(len(map_csns)))\n",
    "    print(\"length of spo2_csns = {}\".format(len(spo2_csns)))\n",
    "\n",
    "    with open(split_file) as json_file:\n",
    "        splits = json.load(json_file) \n",
    "    \n",
    "    if split_type == 'all':\n",
    "        # No abnormalities\n",
    "        final_csns = hr_csns.intersection(spo2_csns)\n",
    "        final_csns = list(final_csns.intersection(map_csns))\n",
    "        print(\"length of final_csns = {}\".format(len(final_csns)))\n",
    "        train_ids = list(set(splits['train_ids']).intersection(set(final_csns)))\n",
    "        val_ids = list(set(splits['val_ids']).intersection(set(final_csns)))\n",
    "        test_ids = list(set(splits['test_ids']).intersection(set(final_csns)))\n",
    "\n",
    "\n",
    "        print(\"\\n-----no abnormalities-----\")\n",
    "        print(\"length of original ids = {}\".format(len(splits['train_ids']) + len(splits['val_ids']) + len(splits['test_ids'])))\n",
    "        print(\"length of train_ids = {}\".format(len(train_ids)))\n",
    "        print(\"length of val_ids = {}\".format(len(val_ids)))\n",
    "        print(\"length of test_ids = {}\".format(len(test_ids)))\n",
    "        print(\"total ids = {}\".format(len(train_ids) + len(val_ids) + len(test_ids)))\n",
    "\n",
    "        d = {'train_ids':train_ids, 'val_ids':val_ids, 'test_ids':test_ids}\n",
    "        # print(\"My Patient ID Dictionary :\", d)\n",
    "        f = open(\"final_ptid_splits_noabnormalities_task_all_\" + time + \".json\", \"w\")\n",
    "        json.dump(d, f)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "    if split_type == 'tachycardia':\n",
    "        # No tachycardia\n",
    "        train_ids = list(set(splits['train_ids']).intersection(set(hr_csns)))\n",
    "        val_ids = list(set(splits['val_ids']).intersection(set(hr_csns)))\n",
    "        test_ids = list(set(splits['test_ids']).intersection(set(hr_csns)))\n",
    "\n",
    "\n",
    "        print(\"\\n-----no tachy-----\")\n",
    "        print(\"length of original ids = {}\".format(len(splits['train_ids']) + len(splits['val_ids']) + len(splits['test_ids'])))\n",
    "        print(\"length of train_ids = {}\".format(len(train_ids)))\n",
    "        print(\"length of val_ids = {}\".format(len(val_ids)))\n",
    "        print(\"length of test_ids = {}\".format(len(test_ids)))\n",
    "        print(\"total ids = {}\".format(len(train_ids) + len(val_ids) + len(test_ids)))\n",
    "\n",
    "        d = {'train_ids':train_ids, 'val_ids':val_ids, 'test_ids':test_ids}\n",
    "        # print(\"My Patient ID Dictionary :\", d)\n",
    "        f = open(\"final_ptid_splits_noabnormalities_task_tachycardia_\" + time + \".json\", \"w\")\n",
    "        json.dump(d, f)\n",
    "        f.close()\n",
    "\n",
    "    if split_type == 'hypotension':\n",
    "        # No hypotension\n",
    "        train_ids = list(set(splits['train_ids']).intersection(set(map_csns)))\n",
    "        val_ids = list(set(splits['val_ids']).intersection(set(map_csns)))\n",
    "        test_ids = list(set(splits['test_ids']).intersection(set(map_csns)))\n",
    "\n",
    "\n",
    "        print(\"\\n-----no hypotension-----\")\n",
    "        print(\"length of original ids = {}\".format(len(splits['train_ids']) + len(splits['val_ids']) + len(splits['test_ids'])))\n",
    "        print(\"length of train_ids = {}\".format(len(train_ids)))\n",
    "        print(\"length of val_ids = {}\".format(len(val_ids)))\n",
    "        print(\"length of test_ids = {}\".format(len(test_ids)))\n",
    "        print(\"total ids = {}\".format(len(train_ids) + len(val_ids) + len(test_ids)))\n",
    "\n",
    "        d = {'train_ids':train_ids, 'val_ids':val_ids, 'test_ids':test_ids}\n",
    "        # print(\"My Patient ID Dictionary :\", d)\n",
    "        f = open(\"final_ptid_splits_noabnormalities_task_hypotension_\" + time + \".json\", \"w\")\n",
    "        json.dump(d, f)\n",
    "        f.close()\n",
    "\n",
    "    if split_type == 'hypoxia':\n",
    "        # No hypoxia\n",
    "        train_ids = list(set(splits['train_ids']).intersection(set(spo2_csns)))\n",
    "        val_ids = list(set(splits['val_ids']).intersection(set(spo2_csns)))\n",
    "        test_ids = list(set(splits['test_ids']).intersection(set(spo2_csns)))\n",
    "\n",
    "\n",
    "        print(\"\\n-----no hypoxia-----\")\n",
    "        print(\"length of original ids = {}\".format(len(splits['train_ids']) + len(splits['val_ids']) + len(splits['test_ids'])))\n",
    "        print(\"length of train_ids = {}\".format(len(train_ids)))\n",
    "        print(\"length of val_ids = {}\".format(len(val_ids)))\n",
    "        print(\"length of test_ids = {}\".format(len(test_ids)))\n",
    "        print(\"total ids = {}\".format(len(train_ids) + len(val_ids) + len(test_ids)))\n",
    "\n",
    "        d = {'train_ids':train_ids, 'val_ids':val_ids, 'test_ids':test_ids}\n",
    "        # print(\"My Patient ID Dictionary :\", d)\n",
    "        f = open(\"final_ptid_splits_noabnormalities_task_hypoxia_\" + time + \".json\", \"w\")\n",
    "        json.dump(d, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86c1dc-e0c7-499e-959d-1561dfb03061",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_hr_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_hr_normal.csv'\n",
    "normal_map_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_map_normal.csv'\n",
    "normal_spo2_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_spo2_normal.csv'\n",
    "\n",
    "all_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_all.json\"\n",
    "hr_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_HR.json\"\n",
    "map_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_MAP.json\"\n",
    "spo2_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_SPO2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37bb64-96d0-4f0e-bf0b-35fedcc2b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_abnormals(all_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c61e7e-d2f8-4866-8a54-c6d494d8425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_abnormals(hr_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"tachycardia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd70ff8-2c1e-48fc-8a53-f6e25c7e84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_abnormals(map_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"hypotension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e96819-61ea-475e-8cd2-dc5014f931fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_abnormals(spo2_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"hypoxia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae027c-9051-406c-8317-67edb31fb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_hr_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_hr_normal.csv'\n",
    "normal_map_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_map_normal.csv'\n",
    "normal_spo2_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_spo2_normal.csv'\n",
    "hr_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_HR.json\"\n",
    "map_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_MAP.json\"\n",
    "spo2_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_SPO2.json\"\n",
    "all_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_all_90min.json\"\n",
    "remove_abnormals(all_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"all\", \"90min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e8b8c-6b86-419e-b1a9-0a4b10dd79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_hr_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_hr_normal.csv'\n",
    "normal_map_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_map_normal.csv'\n",
    "normal_spo2_csn_file = '/deep/group/ed-monitor-self-supervised/v4/downstream.15min.60min.60sec.initial_spo2_normal.csv'\n",
    "hr_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_HR.json\"\n",
    "map_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_MAP.json\"\n",
    "spo2_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_SPO2.json\"\n",
    "all_split_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noNaN_all_120min.json\"\n",
    "remove_abnormals(all_split_file, normal_hr_csn_file, normal_map_csn_file, normal_spo2_csn_file, \"all\", \"120min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf374e9e-d922-48b4-8483-655cd51ffb45",
   "metadata": {},
   "source": [
    "## Check Number of Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30848fb-2064-4a1c-83b9-2a9509415ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events(split_file, label_file, split_type):\n",
    "    \n",
    "    with open(split_file) as f:\n",
    "        splits = json.load(f)\n",
    "\n",
    "    train = np.array(splits['train_ids'])\n",
    "    val = np.array(splits['val_ids'])\n",
    "    test = np.array(splits['test_ids'])\n",
    "    labels = pd.read_csv(label_file)\n",
    "    all_pts = np.array(labels.CSN)\n",
    "    indicies_train = np.where(np.isin(all_pts, train))\n",
    "    indicies_val = np.where(np.isin(all_pts, val))\n",
    "    indicies_test = np.where(np.isin(all_pts, test))\n",
    "    labels_train = labels.iloc[indicies_train]\n",
    "    labels_val = labels.iloc[indicies_val]\n",
    "    labels_test = labels.iloc[indicies_test]\n",
    "    \n",
    "    if split_type == 'tachycardia' or split_type == 'all':\n",
    "        train_num = np.sum(labels_train.HR > 110)          \n",
    "        val_num = np.sum(labels_val.HR > 110)\n",
    "        test_num = np.sum(labels_test.HR > 110)\n",
    "        \n",
    "        print(f\"Train Tachycardic Pts = {train_num}\\nVal Tachycardic Pts = {val_num}\\nTest Tachycardic Pts = {test_num}\")\n",
    "        \n",
    "    if split_type == 'hypotension'or split_type == 'all':\n",
    "        train_num = np.sum(labels_train.MAP < 65)          \n",
    "        val_num = np.sum(labels_val.MAP < 65)\n",
    "        test_num = np.sum(labels_test.MAP < 65)\n",
    "        \n",
    "        print(f\"Train Hypotensive Pts = {train_num}\\nVal Hypotensive Pts = {val_num}\\nTest Hypotensive Pts = {test_num}\")\n",
    "    \n",
    "    if split_type == 'hypoxia' or split_type == 'all':\n",
    "        train_num = np.sum(labels_train.SPO2 < 90)          \n",
    "        val_num = np.sum(labels_val.SPO2 < 90)\n",
    "        test_num = np.sum(labels_test.SPO2 < 90)\n",
    "\n",
    "        print(f\"Train Hypoxic Pts = {train_num}\\nVal Hypoxic Pts = {val_num}\\nTest Hypoxic Pts = {test_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21247093-77f8-4d72-9186-27ae09a5fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_60min_labels_052722.csv\"\n",
    "label_file_old = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_60min_labels.csv\"\n",
    "tachy_split = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_tachycardia.json\"\n",
    "hypotension_split = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_hypotension.json\"\n",
    "hypoxia_split = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_hypoxia.json\"\n",
    "all_split = \"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_all.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63bb55-effb-4f39-858b-cd44659af813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts (120 min)----\")\n",
    "num_events(\"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_all_120min.json\", label_file, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330319dc-8f0d-4b4b-94e7-4d1d824ce01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts (90 min)----\")\n",
    "num_events(\"/deep/group/ed-monitor-self-supervised/test_models_v1/final_ptid_splits_noabnormalities_task_all_90min.json\", label_file, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fecd7-3b0d-4729-b220-bd81d5254a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts----\")\n",
    "num_events(all_split, label_file, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4e030-7ebb-4fa5-877e-0e80206b7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts----\")\n",
    "num_events(tachy_split, label_file, \"tachycardia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba22786-a16f-4c05-9286-e74b0d6801de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Old Counts----\")\n",
    "num_events(\"data_v4_ptid_splits_noabnormalities_task_tachycardia.json\", label_file_old, \"tachycardia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d93e99-c9e0-4809-8a76-d78579e07091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts----\")\n",
    "num_events(hypotension_split, label_file, \"hypotension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506103e4-a084-4cdb-ae88-694c842fc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Old Counts----\")\n",
    "num_events(\"data_v4_ptid_splits_noabnormalities_task_hypotension.json\", label_file_old, \"hypotension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3710491-c14b-4ecf-880d-61944c5af118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Final Counts----\")\n",
    "num_events(hypoxia_split, label_file, \"hypoxia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7579f98-cf48-45c3-96bf-20a795f58c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----Old Counts----\")\n",
    "num_events(\"data_v4_ptid_splits_noabnormalities_task_hypoxia.json\", label_file_old, \"hypoxia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
